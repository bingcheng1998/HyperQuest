{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient2Image(W1):\n",
    "    G = W1.reshape( 32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    maxg = G.max()\n",
    "    ming = G.min()\n",
    "    if np.isinf(ming) or np.isinf(maxg):\n",
    "        G = np.ones(G.shape)*154\n",
    "    else:\n",
    "        G = (G - ming)/(maxg-ming)*255\n",
    "        \n",
    "    \n",
    "    return (G).astype(np.int).tolist()\n",
    "\n",
    "def float_list2int(ll):\n",
    "    ll = ll[np.logical_not(np.isnan(ll))]\n",
    "    kk = ll[np.logical_not(np.isinf(ll))]\n",
    "\n",
    "#     kk = (ll*1e6).astype(np.int)\n",
    "#     kk[kk > 65088000000] = 65088000000\n",
    "#     kk[kk < 0] = np.iinfo(np.int).max\n",
    "#     print(kk[-10:])\n",
    "    return kk.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.encoder.FLOAT_REPR =lambda x:format(x,'.3f')\n",
    "    \n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def encode(self, obj):\n",
    "        if isinstance(obj, float):\n",
    "            return format(obj, '.2f')\n",
    "        return json.JSONEncoder.encode(self, obj)\n",
    "    \n",
    "def save2json(hs, bs, lr, reg, num_epoch, val_acc, W1, stats):\n",
    "    data = {\n",
    "        \"hs\": hs,\n",
    "        \"bs\": bs,\n",
    "        \"lr\": lr,\n",
    "        \"reg\": reg,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"num_epoch\": num_epoch,\n",
    "        \"train_acc_history\": float_list2int(stats[\"train_acc_history\"]),\n",
    "        \"val_acc_history\": float_list2int(stats[\"val_acc_history\"]),\n",
    "        \n",
    "        \"W1\": gradient2Image(W1),\n",
    "        \"loss_history\": float_list2int(stats[\"loss_history\"]),\n",
    "    }\n",
    "#     if json_exist(hs, bs, lr, reg, num_epoch):\n",
    "#         return\n",
    "    with open(f'json/{hs}-{bs}-{lr}-{reg}-{num_epoch}.json', 'w') as f:\n",
    "#         json.dump(data, f, indent=1)\n",
    "        json.dump(data, f,separators=(',', ':'))\n",
    "\n",
    "hs, bs, lr, reg, num_epoch, val_acc, W1, stats = get_pickle(3, 10, 0.004, 0, 8)\n",
    "\n",
    "save2json(hs, bs, lr, reg, num_epoch, val_acc, W1, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "hidden_size = [3, 5, 10, 50, 150]\n",
    "# batch_size = [10, 50, 100, 200, 300, 400]\n",
    "batch_size = [10, 50, 100, 200, 400]\n",
    "# learning_rate = [4.5e-3, 4e-3, 3.5e-3, 3e-3, 2e-3, 1e-3, 5e-4, 1e-4]\n",
    "# learning_rate = [4e-3, 3e-3, 1e-3, 5e-4, 1e-4]\n",
    "learning_rate = [3e-3]\n",
    "# regularization = [0, 0.1, 0.5, 1, 3, 5, 10]\n",
    "regularization = [0, 0.1, 0.5, 1, 10]\n",
    "num_epoch = 8\n",
    "\n",
    "dtype = np.half\n",
    "for lr in learning_rate:\n",
    "    for bs in batch_size:\n",
    "        for hs in hidden_size:\n",
    "            for reg in regularization:\n",
    "                if pickle_exist(hs, bs, lr, reg, num_epoch):\n",
    "                    hs, bs, lr, reg, num_epoch, val_acc, W1, stats = get_pickle(hs, bs, lr, reg, num_epoch)\n",
    "                    save2json(hs, bs, lr, reg, num_epoch, val_acc, W1, stats)\n",
    "#                     print(f'For hs={hs}, bs={bs}, lr={lr}, reg={reg}, val_acc = {val_acc}')\n",
    "                else:\n",
    "                    print(f'For hs={hs}, bs={bs}, lr={lr}, reg={reg}, there is no data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_general_pickle(hs, bs, lr, reg, num_epoch, val_acc, W1, stats):\n",
    "#     W1 = W1.tolist()\n",
    "#     for key in stats.keys():\n",
    "#         stats[key] = stats[key].tolist()\n",
    "#     obj = (hs, bs, lr, reg, num_epoch, val_acc, W1, stats)\n",
    "#     filename = f'json/{hs}-{bs}-{lr}-{reg}-{num_epoch}.pickle'\n",
    "#     savedb(obj,filename)\n",
    "    \n",
    "# save_general_pickle(hs, bs, lr, reg, num_epoch, val_acc, W1, stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
